---
title: "contrast_pattern"
author: "Taewan Kim"
date: "5/6/2021"
output: html_document
---

```{r}
library(reshape2) # melt function
library(ggplot2) # ggplot function
library(pcaPP) # Fast Kendall function
library(energy) # Distance Correlation
library(Hmisc) # Hoeffding's D measure
library(entropy) # Mutual Information
library(zebu) # Normalized Mutual Information
library(minerva) # Maximum Information Coefficient
library(XICOR) # Chatterjee's Coefficient
library(dHSIC) # Hilbert Schmidt Independence Criterion
library(VineCopula) # Blomqvist's Beta
```

```{r}
my_beta <- function(x, y){
    # following Blomqvist, N. (1950).  On a measure of dependence between two
    # random variables. The Annals of Mathematical Statistics, 21(4), 593-600.
    mx <- median(x); my <- median(y)
    n1 <- sum(x < mx & y > my) +  sum(x > mx & y < my)
    n2 <- sum(x < mx & y < my) +  sum(x > mx & y > my)
    
    return ((n1 - n2)/(n1 + n2))
 
}
my_XICOR <- function(x, y){
  return(max(XICOR::calculateXI(x,y), XICOR::calculateXI(y,x)))
}
```

```{r}
get_measures <- function(dat){
  pearson_cor <- stats::cor(dat, method = "pearson")[1,2]
  spearman_cor <- stats::cor(dat, method = "spearman")[1,2]
  kendall_cor <- pcaPP::cor.fk(dat)[1,2]
  dist_cor <- energy::dcor(dat[,1], dat[,2])
  hoeff_cor <- Hmisc::hoeffd(dat[,1], dat[,2])$D[1,2]
  
  MI_cor <- entropy::mi.empirical(entropy::discretize2d(as.matrix(dat[, 1]),
                                                           as.matrix(dat[, 2]),
                                                           numBins1 = 10, numBins2 = 10))
  MIC_cor <- minerva::mine(dat)$MIC[1,2]
  XICOR_cor <- my_XICOR(dat[,1], dat[,2])
  HSIC_cor <- dHSIC::dhsic(dat[,1], dat[, 2])$dHSIC
  beta_cor <- my_beta(dat[, 1], dat[, 2])
  return(c(pearson_cor, spearman_cor, kendall_cor, dist_cor, hoeff_cor,
           MI_cor, MIC_cor, XICOR_cor, HSIC_cor, beta_cor))
}

compare_MI <- function(dat){
  MI_cor <- entropy::mi.empirical(entropy::discretize2d(as.matrix(dat[, 1]),
                                                           as.matrix(dat[, 2]),
                                                           numBins1 = 10, numBins2 = 10))
  NMI_cor <- (zebu::lassie(dat, continuous=c(1,2), breaks = 10, measure = "npmi"))$global
  MIC_cor <- minerva::mine(dat)$MIC[1,2]
  return (c(MI_cor, NMI_cor, MIC_cor))
}
```

# Lollipop that has higher than 1 of previous mutual information

## To compare previous MI, normalized MI, and MIC 

```{r}
set.seed(15)
new_lollipop4 <- function(n){
  t(sapply(1:n, function(i){
    # generate "cluster" assignment
    k <- sample(1:2, 1)
    
    # generate "ball"
    if(k == 1){
      x <- stats::rnorm(1, mean = 0, sd = 1)
      y <- stats::rnorm(1, mean = 0, sd = 1)
      
    } else {
      # k == 2, generate "stick"
      x <- stats::rnorm(1, mean = 6, sd = 4)
      y <- x + stats::rnorm(1, mean = 1, sd = 0.5)
    }
        
    c(x,y)
  }))
}
```

```{r}
new_pop4 <- new_lollipop4(500)
plot(new_pop4)
```

```{r}
lollipop_MI <- matrix(compare_MI(new_pop4), nrow=1, ncol=3)
colnames(lollipop_MI) <- c("Prev_MI", "NMI", "MIC")
rownames(lollipop_MI) <- c("Value")

lollipop_MI
```

# HSIC Check

## Get experimental lollipop

```{r}
new_lollipop1 <- function(n){
  t(sapply(1:n, function(i){
    # generate "cluster" assignment
    k <- sample(1:3, 1)
    
    # generate "ball"
    if(k == 1){
      x <- stats::rnorm(1, mean = 0, sd = 1)
      y <- stats::rnorm(1, mean = 0, sd = 1)
    
      # generate "bridge"
    } else if (k == 2){
      x <- stats::rnorm(1, mean = 1, sd = 0.5)
      y <- stats::rnorm(1, mean = 2, sd = 0.5)
      
    } else {
      # k == 3, generate "stick"
      x <- stats::rnorm(1, mean = 3, sd = 0.8)
      y <- x + stats::rnorm(1, mean = 1, sd = 0.5)
    } 
    
    c(x,y)
  }))
}
```

```{r}
lollipop1 <- new_lollipop1(500)
plot(lollipop1)
```


## MY HSIC fun

```{r}
gaussian_kernel <- function(u, v){
  1/sqrt(2*pi) * exp(-1/2 * (u^2 + v^2))
}

x <- lollipop1[,1]; y <- lollipop1[,2];

term1 <- function(x, y){
  sum <- 0
  len <- length(x)
    
  for (i in 1:len){
    for (j in (i:len)){
      if (i == j){
        next
      }
      sum = sum + gaussian_kernel(x[i], x[j]) * gaussian_kernel(y[i], y[j])
    }
  }
  ans = sum / choose(len,2)
  return (ans)
}

term2 <- function(x, y){
  sum1 <- 0; sum2 <- 0;
  len <- length(x)
  
  for (i in 1:len){
    for (j in (i:len)){
      sum1 <- sum1 + gaussian_kernel(x[i], x[j])
    }
  }
  
  for (i in 1:len){
    for (j in (i:len)){
      sum2 <- sum2 + gaussian_kernel(y[i], y[j])
    }
  }
  
  ans = (sum1/ choose(len,2)) * (sum2/choose(len,2))
  
  return (ans)
}

term3 <- function(x, y){
  total <- 0
  len <- length(x)
  
  for (i in 1:len){
    for (ii in 1:len){
      sum1 <- 0; sum2 <- 0;
      
      for (j in 1:len){
        if (i == j){
          next
        }
        sum1 <- sum1 + gaussian_kernel(x[i], x[j])
      }
      
      for (jj in 1:len){
        if (ii == jj){
          next
        }
        sum2 <- sum2 + gaussian_kernel(y[ii], y[jj])
      }
      
      total <- total + (sum1 / (len - 1)) * (sum2 / (len-1))
    }
  }
  
  total <- total / (len^2)
}

my_HSIC <- function(x,y){
  term1(x,y) + term2(x,y) - 2*term3(x,y)
}
```


```{r}
myfun_HSIC <- my_HSIC(x,y)
package_HSIC <- dHSIC::dhsic(x,y)$dHSIC

print(myfun_HSIC)
print(package_HSIC)
```