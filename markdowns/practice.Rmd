---
title: "Research_Practice"
output: 
  html_document:
    toc:  true
    toc_float:  true
    code_folding:  show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This documnet is a practice analysis on Ziesel dataset

# Data Import

## Import dataset

```{r, cache=TRUE}
# Import Ziesel dataset
dat <- read.csv("Zeisel_preprocessed.csv", row.names = 1)
cell_type <- read.table("Zeisel_cell_info.txt", sep = "\t", header = 1)

# Get the labels for each cell
cluster_labels <- as.numeric(as.factor(cell_type$level1class))
```

```{r}
rand_ind <- sample(nrow(dat), 300)
sub_dat <- dat[rand_ind, ]

sub_celltype <- cell_type[rand_ind, ]
sub_cluster_labels <- as.numeric(as.factor(sub_celltype$level1class))
```

# Dependence Measures

## 1.	Pearson’s correlation coefficient

- it measures the linear dependence.
- the runtime is very short compared to other methods.

```{r}
cor_pearson_mat <- stats::cor(sub_dat, method = "pearson")

cor_pearson_mat[upper.tri(cor_pearson_mat, diag = T)] <- NA
cor_pearson_mat[1:5,1:5]
```

```{r}
# plot the smallest correlations
cor_pearson_vec <- sort(abs(cor_pearson_mat), decreasing = T)
plot(cor_pearson_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_pearson_mat) == cor_pearson_vec[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_pearson_mat[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_pearson_mat) == rev(cor_pearson_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_pearson_mat[idx1, idx2], 3)))
}
```

## 2.	Spearman’s correlation coefficient

- captures monotonous relationship within data.
- the runtime is very short compared to other methods.

```{r}
cor_spearman_mat <- stats::cor(sub_dat, method = "spearman")

cor_spearman_mat[upper.tri(cor_spearman_mat, diag = T)] <- NA
cor_spearman_mat[1:5,1:5]
```


```{r}
# plot the smallest correlations
cor_spearman_vec <- sort(abs(cor_spearman_mat), decreasing = T)
plot(cor_spearman_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_spearman_mat) == cor_spearman_vec[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_spearman_mat[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_spearman_mat) == rev(cor_spearman_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_spearman_mat[idx1, idx2], 3)))
}
```

## 3.	Kendall’s correlation coefficient, τ

- alternative method to Spearman’s correlations, identifying monotonic relationships.
- it takes more time than Pearson and Spearman do, so I decide to apply this method on the subset of dataset of which the size is 300 rows. 

```{r, cache=TRUE}
cor_kendall_mat <- stats::cor(sub_dat, method = "kendall")

cor_kendall_mat[upper.tri(cor_kendall_mat, diag = T)] <- NA
cor_kendall_mat[1:5,1:5]
```

```{r}
# plot the smallest correlations
cor_kendall_vec <- sort(abs(cor_kendall_mat), decreasing = T)
plot(cor_kendall_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_kendall_mat) == cor_kendall_vec[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_kendall_mat[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(cor_kendall_mat) == rev(cor_kendall_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(cor_kendall_mat[idx1, idx2], 3)))
}
```

## 4.	Distance correlation

- it is a fully non-parametric measure that identifies non-linear relationships between two random variables with energy distances

```{r cachedChunk, cache=TRUE}
library(energy)

dist_cor_mat <- matrix(nrow = ncol(sub_dat), ncol = ncol(sub_dat))

for (i in 2:ncol(sub_dat)){
  for (j in 1:(i-1)){
    dist_cor_mat[i,j] <- dcor(as.numeric(sub_dat[, i]), as.numeric(sub_dat[, j]))
  }
}

```

```{r}
dist_cor_mat[upper.tri(dist_cor_mat, diag = T)] <- NA
dist_cor_mat[1:5,1:5]
```

```{r}
# plot the smallest correlations
dist_cor_vec <- sort(abs(dist_cor_mat), decreasing = T)
plot(dist_cor_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(dist_cor_mat) == dist_cor_vec[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(dat[,idx1], dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(dist_cor_mat[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(dist_cor_mat) == rev(dist_cor_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(dat[,idx1], dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(dist_cor_mat[idx1, idx2], 3)))
}
```

## 5. Hoeffding’s D measure

- tests the independence of the data sets by calculating the distance between the product of the marginal distributions

```{r, cache=TRUE}
library(Hmisc)

hoeffd_cor_mat <- hoeffd(x = as.matrix(sub_dat))

hoeff_dist <- hoeffd_cor_mat$D

#hoeff_dist

```

```{r}
# plot the smallest correlations
cor_hoeff_vec <- sort(abs(hoeff_dist), decreasing = T)
plot(cor_hoeff_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(hoeff_dist) == (cor_hoeff_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(hoeff_dist[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(hoeff_dist) == rev(cor_hoeff_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[1,2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(hoeff_dist[idx1, idx2], 3)))
}
```

## 6.	Mutual information (MI)

- measures how much one random variable tells us about another.

```{r, cache=TRUE, warning=FALSE}
library(entropy)

mi_cor_mat <- matrix(nrow = ncol(sub_dat), ncol = ncol(sub_dat))

for (i in 1:ncol(sub_dat)){
  for (j in 1:ncol(sub_dat)){
    y2d <- discretize2d(as.matrix(sub_dat[, i]),
                                   as.matrix(sub_dat[, j]),
                                   numBins1 = 20,
                                   numBins2 = 20)
    mi_cor_mat[i,j] <- as.numeric(mi.empirical(y2d))
  }
}

```

```{r}
# plot the smallest correlations
cor_mi_vec <- sort(abs(mi_cor_mat), decreasing = T)
plot(cor_mi_vec)
```

```{r}
#plot the high correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(mi_cor_mat) == (cor_mi_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[1,2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(mi_cor_mat[idx1, idx2], 3)))
}
```

```{r}
#plot the lowest correlations
par(mfrow = c(2,2))
for(i in 1:4){
 idx <- which(abs(mi_cor_mat) == rev(cor_mi_vec)[i], arr.ind = T)
 idx1 <- idx[1]; idx2 <- idx[1,2]
 
 plot(sub_dat[,idx1], sub_dat[,idx2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[idx1], ", (", idx1, ")"),
      ylab = paste0(colnames(dat)[idx2], ", (", idx2, ")"), 
      main = paste0("Correlation of ", round(mi_cor_mat[idx1, idx2], 3)))
}
```

## (HSIC)

```{r}
library(dHSIC)

dhsic(sub_dat)

```

# Find the indices that have the contrast measure of dependency.

```{r}
# low pearson and high spearman
cor_contrast1 <- (abs(cor_pearson_mat) < 0.3) & (abs(cor_spearman_mat) > 0.7)
cor_contrast_ind1 <- which(cor_contrast1, arr.ind = T)

# high pearson and low spearman
cor_contrast2 <- (abs(cor_pearson_mat) > 0.7) & (abs(cor_spearman_mat) < 0.2)
cor_contrast_ind2 <- which(cor_contrast2, arr.ind = T)

# low pearson and high kendall
cor_contrast3 <- (abs(cor_pearson_mat) < 0.2) & (abs(cor_kendall_mat) > 0.7)
cor_contrast_ind3 <- which(cor_contrast3, arr.ind = T)

# high pearson and low kendall
cor_contrast4 <- (abs(cor_pearson_mat) > 0.7) & (abs(cor_kendall_mat) < 0.2)
cor_contrast_ind4 <- which(cor_contrast4, arr.ind = T)

# low pearson and high distance correlation
cor_contrast5 <- (abs(cor_pearson_mat) < 0.2) & (dist_cor_mat > 0.6)
cor_contrast_ind5 <- which(cor_contrast5, arr.ind = T)

# high pearson and low distance correlation
cor_contrast6 <- (abs(cor_pearson_mat) > 0.6) & (dist_cor_mat < 0.4)
cor_contrast_ind6 <- which(cor_contrast6, arr.ind = T)
```

## Visualization of low pearson(<0.3) and high spearman(>0.7)

```{r}
par(mfrow = c(2, 3))
for (i in 1:nrow(cor_contrast_ind1)){
   index1 <- cor_contrast_ind1[i, 1]; index2 <- cor_contrast_ind1[i, 2]
   plot(sub_dat[,index1], sub_dat[,index2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[index1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[index2], ", (", idx2, ")"), 
      main = paste(paste0("Pearson of ", round(cor_pearson_mat[index1, index2], 3)),
                   "\n",
                   paste0("Spearman of ", round(cor_spearman_mat[index1, index2], 3))))
}
```

## Visualization of low pearson(<0.2) and high distance correlation(>0.6)

```{r}

par(mfrow = c(2, 3))

for (i in 1:nrow(cor_contrast_ind5)){
   index1 <- cor_contrast_ind5[i, 1]; index2 <- cor_contrast_ind5[i, 2]
   plot(sub_dat[,index1], sub_dat[,index2], col = sub_cluster_labels, asp = T,
      pch = 16, xlab = paste0(colnames(sub_dat)[index1], ", (", idx1, ")"),
      ylab = paste0(colnames(sub_dat)[index2], ", (", idx2, ")"), 
      main = paste(paste0("Pearson of ", round(cor_pearson_mat[index1, index2], 3)),
                   "\n",
                   paste0("Dist.Cor of ", round(dist_cor_mat[index1, index2], 3))))
}
```
